{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus   import wordnet\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/users/iris/rsourty/datasets/wn18rr/train.txt', sep = '\\t', header = None)\n",
    "valid = pd.read_csv('/users/iris/rsourty/datasets/wn18rr/valid.txt', sep = '\\t', header = None)\n",
    "test  = pd.read_csv( '/users/iris/rsourty/datasets/wn18rr/test.txt' , sep = '\\t', header = None)\n",
    "\n",
    "for dataset in [train, valid, test]:\n",
    "    \n",
    "    dataset.columns = ['head', 'relation', 'tail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6845599</td>\n",
       "      <td>_member_of_domain_usage</td>\n",
       "      <td>3754979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>789448</td>\n",
       "      <td>_verb_group</td>\n",
       "      <td>1062739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8860123</td>\n",
       "      <td>_member_of_domain_region</td>\n",
       "      <td>5688486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2233096</td>\n",
       "      <td>_member_meronym</td>\n",
       "      <td>2233338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1371092</td>\n",
       "      <td>_hypernym</td>\n",
       "      <td>1352059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      head                  relation     tail\n",
       "0  6845599   _member_of_domain_usage  3754979\n",
       "1   789448               _verb_group  1062739\n",
       "2  8860123  _member_of_domain_region  5688486\n",
       "3  2233096           _member_meronym  2233338\n",
       "4  1371092                 _hypernym  1352059"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_words(id_token):\n",
    "    \"\"\"\n",
    "    Retrieve words from ids.\n",
    "    ADJ, ADJ_SAT, ADV, NOUN, VERB = \"a\", \"s\", \"r\", \"n\", \"v\"\n",
    "    \"\"\"\n",
    "    for pos in ['n', 'a', 's', 'r', 'v']:\n",
    "        try:\n",
    "            # Original, better\n",
    "            return str(wordnet.synset_from_pos_and_offset(pos, id_token)).split(\"'\")[1]\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:16<00:00,  7.84s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset in tqdm.tqdm([train, valid, test], position = 0):\n",
    "    \n",
    "    for column in ['head', 'tail']:\n",
    "        \n",
    "        dataset[column] = dataset[column].apply(lambda x: retrieve_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train['head'] != '') & (train['head'] != 'nan')]\n",
    "train = train[(train['tail'] != '') & (train['tail'] != 'nan')]\n",
    "\n",
    "valid = valid[valid['head'] != '']\n",
    "valid = valid[valid['tail'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_idx(train, valid, test):\n",
    "    vocabulary = pd.Series()\n",
    "    \n",
    "    for series in [train, valid, test]:\n",
    "    \n",
    "        for column in ['head', 'tail']:\n",
    "    \n",
    "            vocabulary = pd.concat([vocabulary, series[column]])\n",
    "        \n",
    "    vocabulary = pd.DataFrame(vocabulary).drop_duplicates().reset_index(drop = True)\n",
    "    \n",
    "    idx_to_token = vocabulary.to_dict()[0]\n",
    "    \n",
    "    token_to_idx = {xi: i for i, xi in idx_to_token.items()}\n",
    "    \n",
    "    return idx_to_token, token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation_idx(train, valid, test):\n",
    "    \"\"\"\n",
    "    relation_to_idx: dict[original id, sub id]\n",
    "    idx_to_relation: dict[sub id, original id]\n",
    "    \"\"\"\n",
    "    relation = pd.Series()\n",
    "    \n",
    "    for series in [train, valid, test]:\n",
    "    \n",
    "        relation = pd.concat([relation, series['relation']])\n",
    "    \n",
    "    relation = pd.DataFrame(relation).drop_duplicates().reset_index(drop = True)\n",
    "    \n",
    "    idx_to_relation = relation.to_dict()[0]\n",
    "    \n",
    "    relation_to_idx = {xi: i for i, xi in idx_to_relation.items()}\n",
    "    \n",
    "    return idx_to_relation, relation_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_token, token_to_idx = get_token_idx(train, valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_relation, relation_to_idx = get_relation_idx(train, valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [train, valid, test]:\n",
    "    \n",
    "    dataset['relation'] = dataset['relation'].apply(lambda x: relation_to_idx[x])\n",
    "    \n",
    "    for column in ['head', 'tail']:\n",
    "        \n",
    "        dataset[column] = dataset[column].apply(lambda x: token_to_idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>878</td>\n",
       "      <td>7</td>\n",
       "      <td>5374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11738</td>\n",
       "      <td>9</td>\n",
       "      <td>29937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>405</td>\n",
       "      <td>8</td>\n",
       "      <td>16604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10317</td>\n",
       "      <td>4</td>\n",
       "      <td>33804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36120</td>\n",
       "      <td>0</td>\n",
       "      <td>31829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    head  relation   tail\n",
       "0    878         7   5374\n",
       "1  11738         9  29937\n",
       "2    405         8  16604\n",
       "3  10317         4  33804\n",
       "4  36120         0  31829"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_entity   = len(idx_to_token)\n",
    "n_relation = len(relation_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train = shuffle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_teacher_1, train_teacher_2, train_teacher_3 = np.array_split(train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_train_entities(train):\n",
    "    list_training_entities = set()\n",
    "    for index, (w1, _, w2) in train.iterrows():\n",
    "        list_training_entities.add(w1)\n",
    "        list_training_entities.add(w2)\n",
    "    return list(list_training_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_entities_train_teacher_1 = get_list_train_entities(train_teacher_1)\n",
    "list_entities_train_teacher_2 = get_list_train_entities(train_teacher_2)\n",
    "list_entities_train_teacher_3 = get_list_train_entities(train_teacher_3)\n",
    "list_entities_train_teacher = get_list_train_entities(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_teacher_1 = Dataset(\n",
    "    train           = train_teacher_1, \n",
    "    valid           = valid, \n",
    "    test            = test, \n",
    "    token_to_idx    = token_to_idx, \n",
    "    idx_to_token    = idx_to_token, \n",
    "    relation_to_idx = relation_to_idx, \n",
    "    idx_to_relation = idx_to_relation,\n",
    "    list_entities_train = list_entities_train_teacher_1,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_teacher_2 = Dataset(\n",
    "    train           = train_teacher_2, \n",
    "    valid           = valid, \n",
    "    test            = test, \n",
    "    token_to_idx    = token_to_idx, \n",
    "    idx_to_token    = idx_to_token, \n",
    "    relation_to_idx = relation_to_idx, \n",
    "    idx_to_relation = idx_to_relation,\n",
    "    list_entities_train = list_entities_train_teacher_2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_teacher_3 = Dataset(\n",
    "    train           = train_teacher_3, \n",
    "    valid           = valid, \n",
    "    test            = test, \n",
    "    token_to_idx    = token_to_idx, \n",
    "    idx_to_token    = idx_to_token, \n",
    "    relation_to_idx = relation_to_idx, \n",
    "    idx_to_relation = idx_to_relation,\n",
    "    list_entities_train = list_entities_train_teacher_3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/users/iris/rsourty/experiments/distillation/datasets/teacher_1.pickle', 'wb') as handle:\n",
    "    pickle.dump(dataset_teacher_1, handle, protocol = pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/users/iris/rsourty/experiments/distillation/datasets/teacher_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(dataset_teacher_2, handle, protocol = pickle.HIGHEST_PROTOCOL)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/users/iris/rsourty/experiments/distillation/datasets/teacher_3.pickle', 'wb') as handle:\n",
    "    pickle.dump(dataset_teacher_3, handle, protocol = pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_18_rr = Dataset(\n",
    "    train = train, \n",
    "    valid = valid, \n",
    "    test  = test, \n",
    "    token_to_idx = token_to_idx, \n",
    "    idx_to_token = idx_to_token, \n",
    "    relation_to_idx = relation_to_idx, \n",
    "    idx_to_relation = idx_to_relation,\n",
    "    list_entities_train = list_entities_train_teacher,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/users/iris/rsourty/experiments/distillation/datasets/100_wn_18_rr.pickle', 'wb') as handle:\n",
    "    pickle.dump(wordnet_18_rr, handle, protocol = pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3134, 3)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "for percent in tqdm.tqdm([0.20, 0.25, 0.33], position = 0):\n",
    "    sample = train.sample(frac = percent)\n",
    "    list_entities_sample = get_list_train_entities(sample)\n",
    "    dataset = Dataset(\n",
    "        train           = sample, \n",
    "        valid           = valid, \n",
    "        test            = test, \n",
    "        token_to_idx    = token_to_idx, \n",
    "        idx_to_token    = idx_to_token, \n",
    "        relation_to_idx = relation_to_idx, \n",
    "        idx_to_relation = idx_to_relation,\n",
    "        list_entities_train = list_entities_sample,\n",
    "\n",
    "    )\n",
    "    with open(f'/users/iris/rsourty/experiments/distillation/datasets/wn18rr_{percent}_percent.pickle', 'wb') as handle:\n",
    "        pickle.dump(dataset, handle, protocol = pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
