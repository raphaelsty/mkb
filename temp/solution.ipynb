{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teacher            import Teacher\n",
    "from loss               import LogisticLoss\n",
    "from loss               import DistillationLoss\n",
    "from benchmark          import benchmark\n",
    "from template_dataset   import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/DeepGraphLearning/KnowledgeGraphEmbedding\n",
    "import sys\n",
    "sys.path.append('/users/iris/rsourty/github/KnowledgeGraphEmbedding/codes')\n",
    "from dataloader import TrainDataset\n",
    "from dataloader import TestDataset\n",
    "from dataloader import BidirectionalOneShotIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme            import stats\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose gpu\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load each knowledge bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dataset = []\n",
    "\n",
    "for dataset_name in ['teacher_1', 'teacher_2', 'teacher_3']:\n",
    "    \n",
    "    with open(f'/users/iris/rsourty/experiments/distillation/datasets/{dataset_name}.pickle', 'rb') as handle:   \n",
    "\n",
    "        list_dataset.append(pickle.load(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_generator(train, n_entity, n_relation, batch_size, negative_sample_size, cpu_num = 1):\n",
    "\n",
    "        head_loader = DataLoader(\n",
    "            TrainDataset(train, n_entity, n_relation, negative_sample_size, 'head-batch'),\n",
    "            batch_size  = batch_size,\n",
    "            shuffle     = True,\n",
    "            num_workers = max(1, cpu_num//2),\n",
    "            collate_fn  = TrainDataset.collate_fn\n",
    "        )\n",
    "\n",
    "        tail_loader = DataLoader(\n",
    "            TrainDataset(train, n_entity, n_relation, negative_sample_size, 'tail-batch'),\n",
    "            batch_size  = batch_size,\n",
    "            shuffle     = True,\n",
    "            num_workers = max(1, cpu_num//2),\n",
    "            collate_fn  = TrainDataset.collate_fn\n",
    "        )\n",
    "\n",
    "        return BidirectionalOneShotIterator(head_loader, tail_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiples_training_genarator(list_dataset, batch_size, n_entity, n_relation, negative_sample_size):\n",
    "    return [get_training_generator(dataset.get_train(), n_entity, n_relation, batch_size, negative_sample_size) for dataset in list_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testing_generator(train_test_valid, valid, n_entity, n_relation, batch_size, cpu_num):\n",
    "    \n",
    "    head_loader = DataLoader(\n",
    "            TestDataset(\n",
    "                valid,\n",
    "                train_test_valid,\n",
    "                n_entity,\n",
    "                n_relation,\n",
    "                'head-batch'\n",
    "            ),\n",
    "            batch_size  = batch_size,\n",
    "            num_workers = cpu_num,\n",
    "            collate_fn  = TestDataset.collate_fn\n",
    "        )\n",
    "\n",
    "    tail_loader = DataLoader(\n",
    "        TestDataset(\n",
    "            valid,\n",
    "            train_test_valid,\n",
    "            n_entity,\n",
    "            n_relation,\n",
    "            'tail-batch'\n",
    "        ),\n",
    "        batch_size  = batch_size,\n",
    "        num_workers = cpu_num,\n",
    "        collate_fn  = TestDataset.collate_fn,\n",
    "    )  \n",
    "\n",
    "    return head_loader, tail_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE      = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA                = 6\n",
    "ALPHA                = 0.5\n",
    "LEARNING_RATE        = 0.0005\n",
    "MAX_STEPS            = 10000\n",
    "VALID_STEPS          = 1000\n",
    "WARM_UP_STEPS        = MAX_STEPS // 2\n",
    "batch_size = 512\n",
    "hidden_dim = 400\n",
    "negative_sample_size = batch_size * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distillation_sample(positive_sample):\n",
    "    list_sample = []\n",
    "    for _, idx, _ in positive_sample:\n",
    "        x = torch.zeros(11) + 1e-5\n",
    "        x[idx] = 1.\n",
    "        list_sample.append(x)\n",
    "    return torch.stack(list_sample).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "list_teacher     = [] \n",
    "dic_optimizer    = {}\n",
    "dic_optimizer_kd = {}\n",
    "\n",
    "for idx, dataset in enumerate(list_dataset):\n",
    "    \n",
    "    n_entity, n_relation = dataset.get_metadata()\n",
    "    \n",
    "    model = Teacher(\n",
    "        model      = 'RotatE', \n",
    "        n_entity   = n_entity, \n",
    "        n_relation = n_relation, \n",
    "        hidden_dim = hidden_dim, \n",
    "        gamma      = 6, \n",
    "        batch_size = batch_size,\n",
    "    )\n",
    "\n",
    "    model = model.cuda()\n",
    "    \n",
    "    list_teacher.append(model)\n",
    "\n",
    "    dic_optimizer_kd[idx] = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr = 0.0005,\n",
    "    )\n",
    "    \n",
    "    dic_optimizer[idx] = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr = 0.0005,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "teacher_1: 0.000483, teacher_2: 0.000459, teacher_3: 0.000549:  10%|▉         | 999/10000 [05:16<46:33,  3.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher: 0, HITS@10: 0.001319, HITS@1: 0.000165, HITS@3: 0.000495, MR: 21659.902407, MRR: 0.000955\n",
      "Teacher: 1, HITS@10: 0.001319, HITS@1: 0.000165, HITS@3: 0.000495, MR: 21659.907023, MRR: 0.000955\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b92c5db0a6e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mvalid_dataloader_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader_tail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_testing_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_test_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_entity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_relation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader_tail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34mf'{metric}: {score:4f}'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/experiments/distillation/benchmark.py\u001b[0m in \u001b[0;36mbenchmark\u001b[0;34m(model, test_dataloader_head, test_dataloader_tail)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtest_dataloader_tail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader_head\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpositive_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mpositive_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositive_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mhmac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHALLENGE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message = %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_generator = get_multiples_training_genarator(\n",
    "    list_dataset, \n",
    "    batch_size = batch_size, \n",
    "    n_entity   = n_entity, \n",
    "    n_relation = n_relation, \n",
    "    negative_sample_size = negative_sample_size,\n",
    ")\n",
    "\n",
    "progress_bar  = tqdm.tqdm(range(MAX_STEPS), position=0)\n",
    "\n",
    "metrics = {idx: stats.RollingMean(100) for idx, _ in enumerate(list_teacher)}\n",
    "\n",
    "beta = np.array([i for i in range(10000)])\n",
    "\n",
    "beta = beta / max(beta)\n",
    "\n",
    "for step in progress_bar:\n",
    "    \n",
    "    sample_dic   = {}\n",
    "    loss_teacher = {}\n",
    "    \n",
    "    for idx_teacher, (generator, teacher) in enumerate(zip(list_generator, list_teacher)):\n",
    "        \n",
    "        dic_optimizer[idx_teacher].zero_grad()\n",
    "        teacher.train()\n",
    "        \n",
    "        positive_sample, negative_sample, subsampling_weight, mode = next(generator)\n",
    "        \n",
    "        teacher.batch_size = positive_sample.shape[0]\n",
    "        \n",
    "        \"\"\"\n",
    "        positive_sample    = positive_sample.cuda()\n",
    "        negative_sample    = negative_sample.cuda()\n",
    "        subsampling_weight = subsampling_weight.cuda()\n",
    "    \n",
    "        positive_score = teacher(positive_sample)\n",
    "        negative_score = teacher((positive_sample, negative_sample), mode = mode)\n",
    "        \n",
    "        loss = LogisticLoss()(\n",
    "            positive_score, \n",
    "            negative_score, \n",
    "            subsampling_weight, \n",
    "            adversarial_sampling = True,\n",
    "            alpha = 0.5,\n",
    "        )\n",
    "        \"\"\"\n",
    "      \n",
    "        # Construct dataset for KD\n",
    "        sample_distillation = [[torch.tensor([w1, r, w2]) for r in range(n_relation)] for w1, _, w2 in positive_sample.cpu().detach()]\n",
    "        sample_distillation = list(chain.from_iterable(sample_distillation))\n",
    "        sample_distillation = torch.stack(sample_distillation).reshape(positive_sample.shape[0], n_relation, 3).cuda()\n",
    "        sample_dic[f'teacher_{idx_teacher}'] = sample_distillation\n",
    "        \n",
    "        loss = DistillationLoss()(\n",
    "            score_student = teacher(sample_distillation, mode = 'distillation'), \n",
    "            score_teacher = get_distillation_sample(positive_sample),\n",
    "        ) * (1 - beta[step]) \n",
    "        \n",
    "        metrics[idx_teacher].update(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        dic_optimizer[idx_teacher].step()\n",
    "    \n",
    "   \n",
    "    # Compute KD\n",
    "    for idx_student, student in enumerate(list_teacher):\n",
    "        \n",
    "        student.train() \n",
    "        \n",
    "        for idx_teacher, teacher in enumerate(list_teacher):\n",
    "            \n",
    "            if idx_student != idx_teacher:\n",
    "            \n",
    "                dic_optimizer_kd[idx_student].zero_grad()\n",
    "                \n",
    "                teacher.eval()\n",
    "\n",
    "                sample = sample_dic[f'teacher_{idx_teacher}']\n",
    "                \n",
    "                loss_distillation = DistillationLoss()(\n",
    "                    score_student = student(sample, mode = 'distillation'), \n",
    "                    score_teacher = teacher(sample, mode = 'distillation'),\n",
    "                ) * beta[step]\n",
    "                \n",
    "                loss_distillation.backward()\n",
    "         \n",
    "                dic_optimizer_kd[idx_student].step()\n",
    "  \n",
    "    for teacher in list_teacher:\n",
    "        \n",
    "        teacher.train()\n",
    "\n",
    "    progress_bar.set_description(f'teacher_1: {metrics[0].get():4f}, teacher_2: {metrics[1].get():4f}, teacher_3: {metrics[2].get():4f}')\n",
    "\n",
    "    # Evaluation:\n",
    "    if (step + 1) % VALID_STEPS == 0:\n",
    "        \n",
    "        for idx, teacher in enumerate(list_teacher):\n",
    "            \n",
    "            teacher.eval()\n",
    "            \n",
    "            train_test_valid = list_dataset[idx].get_train() + list_dataset[idx].get_valid() + list_dataset[idx].get_test()\n",
    "            \n",
    "            valid_dataloader_head, valid_dataloader_tail = get_testing_generator(train_test_valid, list_dataset[idx].get_valid(), n_entity, n_relation, batch_size = 5, cpu_num = 2)\n",
    "            \n",
    "            score = benchmark(model, valid_dataloader_head, valid_dataloader_tail)\n",
    "            \n",
    "            score = ', '.join(sorted({f'{metric}: {score:4f}' for metric, score in score.items()}))\n",
    "            \n",
    "            print(f'Teacher: {idx}, {score}')\n",
    "\n",
    "            #with open(f'/users/iris/rsourty/experiments/distillation/models/full_distill_teacher_{idx}_{score}.pickle', 'wb') as handle:\n",
    "            \n",
    "            #    pickle.dump(teacher, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4359)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DistillationLoss()(\n",
    "    torch.tensor([[1., 0, 0, 0]]),\n",
    "    torch.tensor([[1, 1000., 1, 1]]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0311e-05, device='cuda:1', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DistillationLoss()(\n",
    "    score_student = teacher(sample_distillation, mode = 'distillation'), \n",
    "    score_teacher = get_distillation_sample(positive_sample),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 11])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher(sample, mode = 'distillation').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Teacher: 0, HITS@10: 0.445763, HITS@1: 0.212496, HITS@3: 0.373393, MR: 7379.405704, MRR: 0.301864\n",
    "Teacher: 1, HITS@10: 0.444939, HITS@1: 0.215298, HITS@3: 0.374382, MR: 7379.378009, MRR: 0.302910\n",
    "Teacher: 2, HITS@10: 0.445928, HITS@1: 0.239862, HITS@3: 0.381800, MR: 7378.842565, MRR: 0.319128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the student:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dataset = []\n",
    "\n",
    "for dataset_name in ['teacher_1.pickle', 'teacher_2.pickle', 'teacher_3.pickle']:\n",
    "    \n",
    "    with open(f'/users/iris/rsourty/experiments/distillation/datasets/{dataset_name}', 'rb') as handle:   \n",
    "        \n",
    "        list_dataset.append(pickle.load(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_teacher = []\n",
    "\n",
    "for model_name in [\n",
    "    'as_described_teacher_0_HITS@10: 0.452357, HITS@1: 0.209034, HITS@3: 0.371085, MR: 6727.271348, MRR: 0.300592.pickle',\n",
    "    'as_described_teacher_1_HITS@10: 0.452852, HITS@1: 0.211672, HITS@3: 0.371579, MR: 6727.253544, MRR: 0.301767.pickle',\n",
    "    'as_described_teacher_2_HITS@10: 0.455490, HITS@1: 0.242994, HITS@3: 0.384438, MR: 6726.608803, MRR: 0.322592.pickle',\n",
    "]:\n",
    "    \n",
    "    with open(f'/users/iris/rsourty/experiments/distillation/models/{model_name}', 'rb') as handle:   \n",
    "        \n",
    "        list_teacher.append(pickle.load(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.040039:   1%|          | 999/100000 [01:53<2:58:20,  9.25it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.336630, HITS@1: 0.106495, HITS@3: 0.329707, MR: 14805.443290, MRR: 0.219217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.008317:   2%|▏         | 1999/100000 [04:27<2:47:42,  9.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.363007, HITS@1: 0.296901, HITS@3: 0.352951, MR: 13588.881965, MRR: 0.327125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.001809:   3%|▎         | 2999/100000 [07:03<2:47:59,  9.62it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.374217, HITS@1: 0.339103, HITS@3: 0.363501, MR: 12878.399110, MRR: 0.353695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000495:   4%|▍         | 3999/100000 [09:40<3:11:32,  8.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.381800, HITS@1: 0.353281, HITS@3: 0.371909, MR: 12410.072041, MRR: 0.364480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000141:   5%|▍         | 4999/100000 [12:14<2:56:16,  8.98it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.386416, HITS@1: 0.357896, HITS@3: 0.373722, MR: 12075.963073, MRR: 0.368463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000041:   6%|▌         | 5998/100000 [14:44<2:40:01,  9.79it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.389878, HITS@1: 0.361853, HITS@3: 0.376855, MR: 11860.862018, MRR: 0.372136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000019:   7%|▋         | 6999/100000 [17:09<2:35:42,  9.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.391032, HITS@1: 0.362677, HITS@3: 0.376690, MR: 11695.227992, MRR: 0.373080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000011:   8%|▊         | 7999/100000 [19:38<3:15:28,  7.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.393010, HITS@1: 0.362842, HITS@3: 0.377844, MR: 11605.498351, MRR: 0.373700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000008:   9%|▉         | 8999/100000 [22:22<2:31:08, 10.04it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.393999, HITS@1: 0.362348, HITS@3: 0.377844, MR: 11544.926805, MRR: 0.373573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000007:  10%|▉         | 9999/100000 [24:37<2:34:00,  9.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.393340, HITS@1: 0.361194, HITS@3: 0.378503, MR: 11473.787339, MRR: 0.373089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000008:  11%|█         | 10998/100000 [27:22<2:28:42,  9.98it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.393834, HITS@1: 0.361194, HITS@3: 0.377844, MR: 11429.408836, MRR: 0.372892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000007:  12%|█▏        | 11998/100000 [29:40<2:32:36,  9.61it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.394164, HITS@1: 0.362183, HITS@3: 0.379163, MR: 11396.493900, MRR: 0.373805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000010:  13%|█▎        | 12999/100000 [32:13<7:45:17,  3.12it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.393999, HITS@1: 0.361523, HITS@3: 0.377844, MR: 11367.324596, MRR: 0.373095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000007:  14%|█▍        | 13998/100000 [34:44<2:44:40,  8.70it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.393834, HITS@1: 0.361853, HITS@3: 0.378503, MR: 11334.284042, MRR: 0.373300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000007:  15%|█▍        | 14999/100000 [37:32<2:21:13, 10.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.394164, HITS@1: 0.361029, HITS@3: 0.378009, MR: 11297.412463, MRR: 0.372716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000005:  16%|█▌        | 15999/100000 [39:50<2:44:53,  8.49it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.393010, HITS@1: 0.360699, HITS@3: 0.377514, MR: 11276.348335, MRR: 0.372360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000006:  17%|█▋        | 16999/100000 [42:24<2:20:25,  9.85it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.393999, HITS@1: 0.360864, HITS@3: 0.376690, MR: 11258.974448, MRR: 0.372546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student: 0.000006:  17%|█▋        | 17156/100000 [43:26<2:25:18,  9.50it/s]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-8761e7259bfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositive_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_relation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositive_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         sample = list(chain.from_iterable(sample\n\u001b[1;32m     51\u001b[0m                                          ))\n",
      "\u001b[0;32m<ipython-input-44-8761e7259bfa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositive_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_relation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositive_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         sample = list(chain.from_iterable(sample\n\u001b[1;32m     51\u001b[0m                                          ))\n",
      "\u001b[0;32m<ipython-input-44-8761e7259bfa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositive_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_relation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositive_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         sample = list(chain.from_iterable(sample\n\u001b[1;32m     51\u001b[0m                                          ))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_entity, n_relation = list_dataset[0].get_metadata()\n",
    "\n",
    "list_generator = get_multiples_training_genarator(\n",
    "    list_dataset, \n",
    "    batch_size = batch_size, \n",
    "    n_entity   = n_entity, \n",
    "    n_relation = n_relation, \n",
    "    negative_sample_size = negative_sample_size,\n",
    ")\n",
    "\n",
    "progress_bar = tqdm.tqdm(range(MAX_STEPS), position=0)\n",
    "\n",
    "metric = stats.RollingMean(100)\n",
    "\n",
    "loss_dic = {}\n",
    "\n",
    "student = Teacher(\n",
    "        model      = 'RotatE', \n",
    "        n_entity   = n_entity, \n",
    "        n_relation = n_relation, \n",
    "        hidden_dim = hidden_dim, \n",
    "        gamma      = 6, \n",
    "        batch_size = batch_size,\n",
    ")\n",
    "\n",
    "student = student.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, student.parameters()),\n",
    "    lr = 0.00005,\n",
    ")\n",
    "\n",
    "distillation_loss = DistillationLoss()\n",
    "\n",
    "for step in progress_bar:\n",
    "    \n",
    "    for idx_teacher, (generator, teacher) in enumerate(zip(list_generator, list_teacher)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        student.train()\n",
    "        teacher.eval()\n",
    "        \n",
    "        positive_sample, _, _, _ = next(generator)\n",
    "        \n",
    "        student.batch_size = positive_sample.shape[0]\n",
    "        teacher.batch_size = positive_sample.shape[0]\n",
    "        \n",
    "        sample = [[torch.tensor([w1, r, w2]) for r in range(n_relation)] for w1, _, w2 in positive_sample]\n",
    "        sample = list(chain.from_iterable(sample\n",
    "                                         ))\n",
    "        sample = torch.stack(sample).reshape(positive_sample.shape[0], n_relation, 3).cuda()\n",
    "        \n",
    "        loss = distillation_loss(\n",
    "            score_student = student(sample, mode = 'distillation'), \n",
    "            score_teacher = teacher(sample, mode = 'distillation'),\n",
    "        )\n",
    "        \n",
    "        metric.update(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "            \n",
    "    progress_bar.set_description(f'Student: {metric.get():4f}')\n",
    "    \n",
    "    # Evaluation:\n",
    "    if (step + 1) % VALID_STEPS == 0:\n",
    "        \n",
    "        \n",
    "        train_test_valid = list_dataset[0].get_valid() + list_dataset[0].get_test()\n",
    "            \n",
    "        for dataset in list_dataset:\n",
    "            \n",
    "            train_test_valid += dataset.get_train()    \n",
    "            \n",
    "        valid_dataloader_head, valid_dataloader_tail = get_testing_generator(train_test_valid, list_dataset[0].get_valid(), n_entity, n_relation, batch_size = 5, cpu_num = 2)\n",
    "    \n",
    "        score = benchmark(student, valid_dataloader_head, valid_dataloader_tail)\n",
    "\n",
    "        score = ', '.join(sorted({f'{metric}: {score:4f}' for metric, score in score.items()}))\n",
    "\n",
    "        print(f'Student: {score}')\n",
    "        \n",
    "        with open(f'/users/iris/rsourty/experiments/distillation/models/student_of_teacher_as_described_{score}.pickle', 'wb') as handle:\n",
    "            \n",
    "            pickle.dump(teacher, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: HITS@10: 0.384438, HITS@1: 0.360204, HITS@3: 0.373228, MR: 12147.641444, MRR: 0.369487\n"
     ]
    }
   ],
   "source": [
    "Student: HITS@10: 0.384438, HITS@1: 0.360204, HITS@3: 0.373228, MR: 12147.641444, MRR: 0.369487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
