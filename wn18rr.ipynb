{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library:\n",
    "#!python setup.py install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdmkr import datasets\n",
    "from kdmkr import distillation\n",
    "from kdmkr import evaluation\n",
    "from kdmkr import loss\n",
    "from kdmkr import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device     = 'cuda'\n",
    "hidden_dim = 500\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn18rr = datasets.WN18RR(\n",
    "    batch_size=512, \n",
    "    negative_sample_size=1024, \n",
    "    shuffle=True, \n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = model.RotatE(\n",
    "    hidden_dim=500, \n",
    "    n_entity=wn18rr.n_entity, \n",
    "    n_relation=wn18rr.n_relation, \n",
    "    gamma=6\n",
    ")\n",
    "teacher = teacher.to(\n",
    "    device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_teacher = torch.optim.Adam(filter(lambda p: p.requires_grad, teacher.parameters()), lr = 0.00005)\n",
    "\n",
    "max_step = 6000\n",
    "\n",
    "bar = tqdm.tqdm(range(1, max_step), position=0)\n",
    "\n",
    "metric = stats.RollingMean(1000)\n",
    "\n",
    "teacher.train()\n",
    "\n",
    "for step in bar:\n",
    "    \n",
    "    optimizer_teacher.zero_grad()\n",
    "    \n",
    "    positive_sample, negative_sample, weight, mode = next(wn18rr)\n",
    "    \n",
    "    positive_sample = positive_sample.to(device)\n",
    "    \n",
    "    negative_sample = negative_sample.to(device)\n",
    "    \n",
    "    weight = weight.to(device)\n",
    "    \n",
    "    positive_score = teacher(sample=positive_sample)\n",
    "    \n",
    "    negative_score = teacher(sample=(positive_sample, negative_sample), mode=mode)\n",
    "    \n",
    "    loss_teacher = loss.Adversarial()(positive_score, negative_score, weight, alpha=0.5)\n",
    "    \n",
    "    loss_teacher.backward()\n",
    "    \n",
    "    optimizer_teacher.step()\n",
    "    \n",
    "    metric.update(loss_teacher.item())\n",
    "    \n",
    "    if step % 5 == 0:\n",
    "        bar.set_description(f'Adversarial loss: {metric.get():6f}')\n",
    "    \n",
    "    if step % 2000 == 0:\n",
    "        \n",
    "        teacher = teacher.eval()\n",
    "        \n",
    "        score = evaluation.Evaluation()(model=teacher, dataset=wn18rr.test_dataset(batch_size=8), device=device)\n",
    "        \n",
    "        teacher = teacher.train()\n",
    "        \n",
    "        print(score)\n",
    "        \n",
    "        # Set path HERE\n",
    "        with open(f'./models/teacher_wn18rr_{score}.pickle', 'wb') as handle:\n",
    "            \n",
    "            pickle.dump(teacher, handle, protocol = pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of the previous training\n",
    "\n",
    "teacher_name = 'teacher_wn18rr_HITS@10: 0.527760, HITS@1: 0.419113, HITS@3: 0.477664, MR: 5509.747288, MRR: 0.457429.pickle'\n",
    "\n",
    "with open(f'./models/{teacher_name}', 'rb') as handle:\n",
    "    \n",
    "    teacher = pickle.load(handle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40000 [00:00<?, ?it/s]/users/iris/rsourty/.local/lib/python3.6/site-packages/torch/nn/functional.py:1958: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "Metric: 0.188103:   2%|▏         | 999/40000 [10:41<6:44:07,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.464582, HITS@1: 0.371091, HITS@3: 0.432674, MR: 6778.074186, MRR: 0.407070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.041273:   5%|▍         | 1999/40000 [22:54<6:17:31,  1.68it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.481174, HITS@1: 0.401404, HITS@3: 0.450862, MR: 5879.874442, MRR: 0.431126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.015341:   7%|▋         | 2999/40000 [35:06<6:15:39,  1.64it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.490587, HITS@1: 0.412412, HITS@3: 0.458360, MR: 5445.871251, MRR: 0.441519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.007602:  10%|▉         | 3999/40000 [47:15<6:02:13,  1.66it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.493299, HITS@1: 0.415922, HITS@3: 0.460913, MR: 5267.437460, MRR: 0.444803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.004311:  12%|█▏        | 4999/40000 [59:27<7:28:31,  1.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.496809, HITS@1: 0.413050, HITS@3: 0.462987, MR: 5066.776005, MRR: 0.444453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.002574:  15%|█▍        | 5999/40000 [1:11:46<6:10:11,  1.53it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.498086, HITS@1: 0.413210, HITS@3: 0.462987, MR: 4950.202936, MRR: 0.445204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.001651:  17%|█▋        | 6999/40000 [1:23:55<6:02:08,  1.52it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.498564, HITS@1: 0.414646, HITS@3: 0.465380, MR: 5058.032068, MRR: 0.447478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.001199:  20%|█▉        | 7999/40000 [1:36:10<5:19:25,  1.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.499043, HITS@1: 0.415922, HITS@3: 0.466496, MR: 5152.536535, MRR: 0.448861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.001016:  22%|██▏       | 8999/40000 [1:48:26<5:20:14,  1.61it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.499362, HITS@1: 0.410976, HITS@3: 0.463625, MR: 5214.182993, MRR: 0.446302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000981:  25%|██▍       | 9999/40000 [2:00:42<5:29:18,  1.52it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.508775, HITS@1: 0.411455, HITS@3: 0.462827, MR: 5242.070676, MRR: 0.446687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.001066:  27%|██▋       | 10999/40000 [2:12:53<4:50:15,  1.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.514199, HITS@1: 0.407307, HITS@3: 0.463784, MR: 5342.028398, MRR: 0.445512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.001068:  30%|██▉       | 11999/40000 [2:25:10<4:44:35,  1.64it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.517869, HITS@1: 0.405392, HITS@3: 0.469368, MR: 5427.585354, MRR: 0.447117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.001068:  32%|███▏      | 12999/40000 [2:37:23<5:24:24,  1.39it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.525048, HITS@1: 0.407307, HITS@3: 0.470325, MR: 5414.229419, MRR: 0.449145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.001056:  34%|███▍      | 13712/40000 [2:46:32<4:37:20,  1.58it/s]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-07d2458a99f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m                   \u001b[0mrelation_distribution_teacher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelation_distribution_teacher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                   \u001b[0mrelation_distribution_student\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelation_distribution_student\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                   \u001b[0mhead_teacher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelation_teacher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail_teacher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             )\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/experiments/kdmkr/kdmkr/distillation/distillation.py\u001b[0m in \u001b[0;36mget_distillation_sample_relation\u001b[0;34m(self, relation_distribution_teacher, relation_distribution_student, head_teacher, relation_teacher, tail_teacher)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;31m# Teacher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mrelation_distribution_teacher_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelation_distribution_teacher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0mrelation_distribution_teacher_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelation_teacher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0missc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# cls is not a class (old Boost; see SF #502085)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0missc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_step = 40000\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "wn18rr = datasets.WN18RR(\n",
    "    batch_size=1000, \n",
    "    negative_sample_size=1, \n",
    "    seed=42, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Increasing the size of latents representations of the student allow to improve results.\n",
    "student = model.RotatE(\n",
    "    hidden_dim=1000, \n",
    "    n_entity=wn18rr.n_entity, \n",
    "    n_relation=wn18rr.n_relation, \n",
    "    gamma=0\n",
    ")\n",
    "\n",
    "student = student.to(device)\n",
    "\n",
    "# Distillation process allow to handle different indexes between the student and the teacher.\n",
    "# Distillation process allow to pre-compute batch dedicated to distillation.\n",
    "distillation_process = distillation.Distillation(\n",
    "    teacher_entities  = wn18rr.entities, \n",
    "    student_entities  = wn18rr.entities, \n",
    "    teacher_relations = wn18rr.relations, \n",
    "    student_relations = wn18rr.relations,\n",
    "    batch_size_entity = 20,\n",
    "    batch_size_relation = 11,\n",
    ")\n",
    "\n",
    "\n",
    "optimizer_student = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, student.parameters()), lr = 0.00005)\n",
    "\n",
    "bar = tqdm.tqdm(range(1, max_step + 1), position=0)\n",
    "\n",
    "# Creme online metric.\n",
    "metric = stats.RollingMean(1000)\n",
    "\n",
    "teacher = teacher.eval()\n",
    "student = student.train()\n",
    "\n",
    "for step in bar:\n",
    "    \n",
    "    optimizer_student.zero_grad()\n",
    "    \n",
    "    positive_sample, negative_sample, weight, mode = next(wn18rr)\n",
    "    \n",
    "    batch_head_teacher = []\n",
    "    batch_head_student = []\n",
    "    \n",
    "    batch_relation_teacher = []\n",
    "    batch_relation_student = []\n",
    "    \n",
    "    batch_tail_teacher = []\n",
    "    batch_tail_student = []\n",
    "    \n",
    "    (\n",
    "         entity_distribution_teacher,\n",
    "         relation_distribution_teacher,\n",
    "         entity_distribution_student,\n",
    "         relation_distribution_student\n",
    "   ) = distillation_process.uniform_subsampling()\n",
    "\n",
    "    \n",
    "    for head, relation, tail in positive_sample:\n",
    "        \n",
    "        head, relation, tail = head.item(), relation.item(), tail.item()\n",
    "        \n",
    "        distillation_available = distillation_process.available(head=head, relation=relation, tail=tail)\n",
    "       \n",
    "        if distillation_available:\n",
    "            \n",
    "            tensor_head_teacher, tensor_head_student = distillation_process.get_distillation_sample_head(\n",
    "                entity_distribution_teacher=entity_distribution_teacher,\n",
    "                entity_distribution_student=entity_distribution_student,\n",
    "                head_teacher=head, relation_teacher=relation, tail_teacher=tail\n",
    "            )\n",
    "             \n",
    "            tensor_relation_teacher, tensor_relation_student = distillation_process.get_distillation_sample_relation(\n",
    "                  relation_distribution_teacher=relation_distribution_teacher,\n",
    "                  relation_distribution_student=relation_distribution_student,\n",
    "                  head_teacher=head, relation_teacher=relation, tail_teacher=tail\n",
    "            )\n",
    "             \n",
    "            tensor_tail_teacher, tensor_tail_student = distillation_process.get_distillation_sample_tail(\n",
    "                  entity_distribution_teacher=entity_distribution_teacher,\n",
    "                  entity_distribution_student=entity_distribution_student,\n",
    "                  head_teacher=head, relation_teacher=relation, tail_teacher=tail\n",
    "            )\n",
    "        \n",
    "            batch_head_teacher.append(tensor_head_teacher)\n",
    "            batch_head_student.append(tensor_head_student)\n",
    "\n",
    "            batch_relation_teacher.append(tensor_relation_teacher)\n",
    "            batch_relation_student.append(tensor_relation_student)\n",
    "\n",
    "            batch_tail_teacher.append(tensor_tail_teacher)\n",
    "            batch_tail_student.append(tensor_tail_student)\n",
    "    \n",
    "    \n",
    "    teacher_head_tensor = distillation_process.stack_entity(batch_head_teacher, device=device)\n",
    "    student_head_tensor = distillation_process.stack_entity(batch_head_student, device=device)\n",
    "    \n",
    "    teacher_relation_tensor = distillation_process.stack_relations(batch_relation_teacher, device=device)\n",
    "    student_relation_tensor = distillation_process.stack_relations(batch_relation_student, device=device)\n",
    "    \n",
    "    teacher_tail_tensor = distillation_process.stack_entity(batch_tail_teacher, device=device)\n",
    "    student_tail_tensor = distillation_process.stack_entity(batch_tail_student, device=device)\n",
    "\n",
    "    # Distillation loss of heads\n",
    "    loss_head = loss.KlDivergence()(\n",
    "        teacher_score=teacher.distill(teacher_head_tensor), \n",
    "        student_score=student.distill(student_head_tensor)\n",
    "    ) \n",
    "    \n",
    "    # Distillation loss of relations.\n",
    "    loss_relation = loss.KlDivergence()(\n",
    "        teacher_score=teacher.distill(teacher_relation_tensor), \n",
    "        student_score=student.distill(student_relation_tensor)\n",
    "    ) \n",
    "    \n",
    "    # Distillation loss of tails.\n",
    "    loss_tail = loss.KlDivergence()(\n",
    "        teacher_score=teacher.distill(teacher_tail_tensor), \n",
    "        student_score=student.distill(student_tail_tensor)\n",
    "    ) \n",
    "    \n",
    "    # The loss of the student is equal to the sum of all losses.\n",
    "    loss_student = loss_head + loss_relation + loss_tail\n",
    "    \n",
    "    metric.update(loss_student.item())\n",
    "    \n",
    "    loss_student.backward()\n",
    "\n",
    "    optimizer_student.step()\n",
    "    \n",
    "    if step % 5 == 0:\n",
    "    \n",
    "        bar.set_description(f'Metric: {metric.get():6f}')\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        \n",
    "        student = student.eval()\n",
    "        \n",
    "        score = evaluation.Evaluation()(model=student, dataset=wn18rr.test_dataset(batch_size=8), device=device)\n",
    "        \n",
    "        print(score)\n",
    "        \n",
    "        with open(f'./models/student_wn18rr_{score}.pickle', 'wb') as handle:\n",
    "            \n",
    "            pickle.dump(student, handle, protocol = pickle.HIGHEST_PROTOCOL)    \n",
    "        \n",
    "        student = student.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
