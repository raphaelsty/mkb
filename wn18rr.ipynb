{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python setup.py install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdmkr import datasets\n",
    "from kdmkr import distillation\n",
    "from kdmkr import evaluation\n",
    "from kdmkr import loss\n",
    "from kdmkr import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device     = 'cuda'\n",
    "hidden_dim = 500\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn18rr = datasets.WN18RR(batch_size=batch_size, negative_sample_size=batch_size*2, shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = model.RotatE(hidden_dim=hidden_dim, n_entity=wn18rr.n_entity, n_relation=wn18rr.n_relation, gamma=6)\n",
    "teacher = teacher.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_teacher = torch.optim.Adam(filter(lambda p: p.requires_grad, teacher.parameters()), lr = 0.00005)\n",
    "\n",
    "max_step = 6000\n",
    "\n",
    "bar = tqdm.tqdm(range(1, max_step), position=0)\n",
    "\n",
    "metric = stats.RollingMean(1000)\n",
    "\n",
    "evaluation = evaluation.Evaluation()\n",
    "\n",
    "teacher.train()\n",
    "\n",
    "for step in bar:\n",
    "    \n",
    "    optimizer_teacher.zero_grad()\n",
    "    \n",
    "    positive_sample, negative_sample, weight, mode = next(wn18rr)\n",
    "    \n",
    "    positive_sample = positive_sample.to(device)\n",
    "    \n",
    "    negative_sample = negative_sample.to(device)\n",
    "    \n",
    "    weight = weight.to(device)\n",
    "    \n",
    "    positive_score = teacher(sample=positive_sample)\n",
    "    \n",
    "    negative_score = teacher(sample=(positive_sample, negative_sample), mode=mode)\n",
    "    \n",
    "    loss_teacher = loss.Adversarial()(positive_score, negative_score, weight, alpha=0.5)\n",
    "    \n",
    "    loss_teacher.backward()\n",
    "    \n",
    "    optimizer_teacher.step()\n",
    "    \n",
    "    metric.update(loss_teacher.item())\n",
    "    \n",
    "    if step % 30 == 0:\n",
    "    \n",
    "        bar.set_description(f'Metric: {metric.get():6f}')\n",
    "    \n",
    "    if step % 2000 == 0:\n",
    "        \n",
    "        teacher = teacher.eval()\n",
    "        \n",
    "        score = evaluation(model=teacher, dataset=wn18rr.test_dataset(batch_size=8), device=device)\n",
    "        \n",
    "        teacher = teacher.train()\n",
    "        \n",
    "        print(score)\n",
    "        \n",
    "        with open(f'/users/iris/rsourty/experiments/kdmkr/models/teacher_wn18rr_{score}.pickle', 'wb') as handle:\n",
    "            \n",
    "            pickle.dump(teacher, handle, protocol = pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of the previous training\n",
    "\n",
    "teacher_name = 'teacher_wn18rr_HITS@10: 0.527760, HITS@1: 0.419113, HITS@3: 0.477664, MR: 5509.747288, MRR: 0.457429.pickle'\n",
    "\n",
    "with open(f'/users/iris/rsourty/experiments/kdmkr/models/{teacher_name}', 'rb') as handle:\n",
    "    \n",
    "    teacher = pickle.load(handle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40000 [00:00<?, ?it/s]/users/iris/rsourty/.local/lib/python3.6/site-packages/torch/nn/functional.py:1958: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "Metric: 0.037566:   2%|▏         | 999/40000 [02:53<1:51:06,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.414008, HITS@1: 0.369177, HITS@3: 0.396937, MR: 10494.610881, MRR: 0.386363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000516:   5%|▍         | 1999/40000 [07:51<1:48:58,  5.81it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.417996, HITS@1: 0.373484, HITS@3: 0.402680, MR: 10160.950064, MRR: 0.390909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000107:   7%|▋         | 2999/40000 [12:50<1:46:10,  5.81it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.419751, HITS@1: 0.373165, HITS@3: 0.402521, MR: 10075.413369, MRR: 0.390913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000131:  10%|▉         | 3999/40000 [17:49<1:46:49,  5.62it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.414805, HITS@1: 0.368858, HITS@3: 0.398692, MR: 9969.183153, MRR: 0.386589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000186:  12%|█▏        | 4999/40000 [22:47<1:38:26,  5.93it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.405712, HITS@1: 0.361040, HITS@3: 0.390077, MR: 9816.358328, MRR: 0.378677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000213:  15%|█▍        | 5999/40000 [27:46<1:37:57,  5.78it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.392310, HITS@1: 0.353063, HITS@3: 0.377473, MR: 9399.855775, MRR: 0.368555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000229:  17%|█▋        | 6999/40000 [32:45<1:32:44,  5.93it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.377313, HITS@1: 0.341576, HITS@3: 0.364231, MR: 8933.670230, MRR: 0.355502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000236:  20%|█▉        | 7999/40000 [37:44<1:32:33,  5.76it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.358488, HITS@1: 0.325622, HITS@3: 0.345884, MR: 8481.211072, MRR: 0.338464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000236:  22%|██▏       | 8999/40000 [42:43<1:27:41,  5.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.342055, HITS@1: 0.310147, HITS@3: 0.330408, MR: 8047.845565, MRR: 0.322884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000237:  25%|██▍       | 9999/40000 [47:42<1:26:41,  5.77it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.317486, HITS@1: 0.291481, HITS@3: 0.307275, MR: 7705.363433, MRR: 0.301756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000230:  30%|██▉       | 11999/40000 [57:39<1:18:49,  5.92it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.276643, HITS@1: 0.252712, HITS@3: 0.267869, MR: 7161.599394, MRR: 0.262655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000231:  32%|███▏      | 12999/40000 [1:02:39<1:19:55,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.263401, HITS@1: 0.244257, HITS@3: 0.254946, MR: 6923.241863, MRR: 0.252174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000225:  34%|███▍      | 13660/40000 [1:06:39<1:16:14,  5.76it/s]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Metric: 0.000203:  47%|████▋     | 18999/40000 [1:32:31<59:10,  5.92it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.172304, HITS@1: 0.156988, HITS@3: 0.165603, MR: 6277.749043, MRR: 0.163818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000193:  50%|████▉     | 19999/40000 [1:37:30<56:57,  5.85it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.154435, HITS@1: 0.141353, HITS@3: 0.149011, MR: 6150.708679, MRR: 0.147561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000190:  52%|█████▏    | 20999/40000 [1:42:29<55:01,  5.76it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.142789, HITS@1: 0.129068, HITS@3: 0.137364, MR: 6173.437779, MRR: 0.135442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000187:  53%|█████▎    | 21389/40000 [1:45:42<53:27,  5.80it/s]    IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Metric: 0.000147:  67%|██████▋   | 26999/40000 [2:12:23<36:51,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.090140, HITS@1: 0.080728, HITS@3: 0.086790, MR: 6074.925814, MRR: 0.085867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000145:  70%|██████▉   | 27999/40000 [2:17:21<33:39,  5.94it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.091576, HITS@1: 0.082642, HITS@3: 0.087907, MR: 6096.272495, MRR: 0.087373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000139:  72%|███████▏  | 28999/40000 [2:22:20<31:19,  5.85it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.084716, HITS@1: 0.076101, HITS@3: 0.081366, MR: 6089.404116, MRR: 0.080664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000135:  73%|███████▎  | 29252/40000 [2:25:09<30:50,  5.81it/s]    IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Metric: 0.000114:  87%|████████▋ | 34999/40000 [2:52:13<14:51,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.058711, HITS@1: 0.050574, HITS@3: 0.055680, MR: 6160.609126, MRR: 0.055069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000111:  90%|████████▉ | 35999/40000 [2:57:12<11:28,  5.81it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.059349, HITS@1: 0.052648, HITS@3: 0.056318, MR: 6175.678845, MRR: 0.056539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000109:  92%|█████████▏| 36999/40000 [3:02:11<08:41,  5.75it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITS@10: 0.056637, HITS@1: 0.051053, HITS@3: 0.054882, MR: 6173.936981, MRR: 0.054732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric: 0.000109:  93%|█████████▎| 37036/40000 [3:04:23<08:22,  5.90it/s]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_batch_size = 1000\n",
    "\n",
    "max_step = 40000\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "wn18rr = datasets.WN18RR(batch_size=student_batch_size, negative_sample_size=1, seed=42, shuffle=True)\n",
    "\n",
    "student = model.RotatE(hidden_dim=1500, n_entity=wn18rr.n_entity, n_relation=wn18rr.n_relation, gamma=0)\n",
    "\n",
    "student = student.to(device)\n",
    "\n",
    "distillation_process = distillation.Distillation(\n",
    "    teacher_entities  = wn18rr.entities, \n",
    "    student_entities  = wn18rr.entities, \n",
    "    teacher_relations = wn18rr.relations, \n",
    "    student_relations = wn18rr.relations,\n",
    ")\n",
    "\n",
    "optimizer_student = torch.optim.Adam(filter(lambda p: p.requires_grad, student.parameters()), lr = 0.00005)\n",
    "\n",
    "bar = tqdm.tqdm(range(1, max_step + 1), position=0)\n",
    "\n",
    "metric = stats.RollingMean(1000)\n",
    "\n",
    "teacher.eval()\n",
    "\n",
    "student.train()\n",
    "\n",
    "kl_divergence = loss.KlDivergence()\n",
    "\n",
    "for step in bar:\n",
    "    \n",
    "    positive_sample, negative_sample, weight, mode = next(wn18rr)\n",
    "    \n",
    "    teacher_relation = []\n",
    "    student_relation = []\n",
    "    \n",
    "    optimizer_student.zero_grad()\n",
    "    \n",
    "    for head, relation, tail in positive_sample:\n",
    "        \n",
    "        head, relation, tail = head.item(), relation.item(), tail.item()\n",
    "\n",
    "        teacher_common_relation_sample, _ = distillation_process.mini_batch_teacher_relation(\n",
    "            head=head, tail=tail)\n",
    "\n",
    "        student_common_relation_sample, _ = distillation_process.mini_batch_student_relation(\n",
    "            teacher_head=head, teacher_tail=tail)\n",
    "\n",
    "        teacher_relation.append(teacher_common_relation_sample)\n",
    "        student_relation.append(student_common_relation_sample)\n",
    "    \n",
    "    teacher_relation_tensor = torch.stack(teacher_relation).reshape(len(teacher_relation), wn18rr.n_relation, 3).to(device)\n",
    "    student_relation_tensor = torch.stack(student_relation).reshape(len(student_relation), wn18rr.n_relation, 3).to(device)\n",
    "    \n",
    "    loss_relation = kl_divergence(\n",
    "        teacher_score=teacher.distill(teacher_relation_tensor), \n",
    "        student_score=student.distill(student_relation_tensor)\n",
    "    ) \n",
    "    \n",
    "    loss_student = loss_relation\n",
    "    \n",
    "    metric.update(loss_student.item())\n",
    "    \n",
    "    loss_student.backward()\n",
    "\n",
    "    optimizer_student.step()\n",
    "    \n",
    "    if step % 7 == 0:\n",
    "    \n",
    "        bar.set_description(f'Metric: {metric.get():6f}')\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        \n",
    "        student = student.eval()\n",
    "        \n",
    "        score = evaluation.Evaluation()(model=student, dataset=wn18rr.test_dataset(batch_size=2), device=device)\n",
    "        \n",
    "        print(score)\n",
    "        \n",
    "        with open(f'/users/iris/rsourty/experiments/kdmkr/models/student_wn18rr_{score}.pickle', 'wb') as handle:\n",
    "            \n",
    "            pickle.dump(student, handle, protocol = pickle.HIGHEST_PROTOCOL)    \n",
    "        \n",
    "        student = student.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
