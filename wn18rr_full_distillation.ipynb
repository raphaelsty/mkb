{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library:\n",
    "#!python setup.py install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdmkr import datasets\n",
    "from kdmkr import distillation\n",
    "from kdmkr import evaluation\n",
    "from kdmkr import loss\n",
    "from kdmkr import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device     = 'cuda'\n",
    "hidden_dim = 500\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn18rr = datasets.WN18RR(\n",
    "    batch_size=512, \n",
    "    negative_sample_size=1024, \n",
    "    shuffle=True, \n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = model.RotatE(\n",
    "    hidden_dim=500, \n",
    "    n_entity=wn18rr.n_entity, \n",
    "    n_relation=wn18rr.n_relation, \n",
    "    gamma=6\n",
    ")\n",
    "teacher = teacher.to(\n",
    "    device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_teacher = torch.optim.Adam(filter(lambda p: p.requires_grad, teacher.parameters()), lr = 0.00005)\n",
    "\n",
    "max_step = 6000\n",
    "\n",
    "bar = tqdm.tqdm(range(1, max_step), position=0)\n",
    "\n",
    "metric = stats.RollingMean(1000)\n",
    "\n",
    "evaluation = evaluation.Evaluation()\n",
    "\n",
    "teacher.train()\n",
    "\n",
    "for step in bar:\n",
    "    \n",
    "    optimizer_teacher.zero_grad()\n",
    "    \n",
    "    positive_sample, negative_sample, weight, mode = next(wn18rr)\n",
    "    \n",
    "    positive_sample = positive_sample.to(device)\n",
    "    \n",
    "    negative_sample = negative_sample.to(device)\n",
    "    \n",
    "    weight = weight.to(device)\n",
    "    \n",
    "    positive_score = teacher(sample=positive_sample)\n",
    "    \n",
    "    negative_score = teacher(sample=(positive_sample, negative_sample), mode=mode)\n",
    "    \n",
    "    loss_teacher = loss.Adversarial()(positive_score, negative_score, weight, alpha=0.5)\n",
    "    \n",
    "    loss_teacher.backward()\n",
    "    \n",
    "    optimizer_teacher.step()\n",
    "    \n",
    "    metric.update(loss_teacher.item())\n",
    "    \n",
    "    if step % 5 == 0:\n",
    "        bar.set_description(f'Adversarial loss: {metric.get():6f}')\n",
    "    \n",
    "    if step % 2000 == 0:\n",
    "        \n",
    "        teacher = teacher.eval()\n",
    "        \n",
    "        score = evaluation(model=teacher, dataset=wn18rr.test_dataset(batch_size=8), device=device)\n",
    "        \n",
    "        teacher = teacher.train()\n",
    "        \n",
    "        print(score)\n",
    "        \n",
    "        # Set path HERE\n",
    "        with open(f'./models/teacher_wn18rr_{score}.pickle', 'wb') as handle:\n",
    "            \n",
    "            pickle.dump(teacher, handle, protocol = pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of the previous training\n",
    "\n",
    "teacher_name = 'teacher_wn18rr_HITS@10: 0.527760, HITS@1: 0.419113, HITS@3: 0.477664, MR: 5509.747288, MRR: 0.457429.pickle'\n",
    "\n",
    "with open(f'./models/{teacher_name}', 'rb') as handle:\n",
    "    \n",
    "    teacher = pickle.load(handle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_batch_size = 1000\n",
    "\n",
    "# Number of entities to consider to distill:\n",
    "batch_size_entity = 10\n",
    "\n",
    "max_step = 40000\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "wn18rr = datasets.WN18RR(\n",
    "    batch_size=1000, \n",
    "    negative_sample_size=1, \n",
    "    seed=42, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Increasing the size of latents representations of the student allow to improve results.\n",
    "student = model.RotatE(\n",
    "    hidden_dim=1000, \n",
    "    n_entity=wn18rr.n_entity, \n",
    "    n_relation=wn18rr.n_relation, \n",
    "    gamma=0\n",
    ")\n",
    "\n",
    "student = student.to(device)\n",
    "\n",
    "# Distillation process allow to handle different indexes between the student and the teacher.\n",
    "# Distillation process allow to pre-compute batch dedicated to distillation.\n",
    "distillation_process = distillation.Distillation(\n",
    "    teacher_entities  = wn18rr.entities, \n",
    "    student_entities  = wn18rr.entities, \n",
    "    teacher_relations = wn18rr.relations, \n",
    "    student_relations = wn18rr.relations,\n",
    ")\n",
    "\n",
    "optimizer_student = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, student.parameters()), lr = 0.00005)\n",
    "\n",
    "bar = tqdm.tqdm(range(1, max_step + 1), position=0)\n",
    "\n",
    "# Creme online metric.\n",
    "metric = stats.RollingMean(1000)\n",
    "\n",
    "teacher = teacher.eval()\n",
    "student = student.train()\n",
    "\n",
    "for step in bar:\n",
    "    \n",
    "    positive_sample, negative_sample, weight, mode = next(wn18rr)\n",
    "    \n",
    "    teacher_head = []\n",
    "    student_head = []\n",
    "    teacher_relation = []\n",
    "    student_relation = []\n",
    "    teacher_tail = []\n",
    "    student_tail = []\n",
    "\n",
    "    optimizer_student.zero_grad()\n",
    "    \n",
    "    for head, relation, tail in positive_sample:\n",
    "        \n",
    "        head, relation, tail = head.item(), relation.item(), tail.item()\n",
    "        \n",
    "        # Constructing the tensor dedicated to distillation of HEAD:\n",
    "        teacher_common_head_sample, _ = distillation_process.mini_batch_teacher_head(\n",
    "            relation=relation, tail=tail)\n",
    "        \n",
    "        # Distillation class make the mapping between entities indexes of the \n",
    "        # student and teacher. For a single sample with relation r_1 and tail t_1, the method below\n",
    "        # return a tensor [(e_1, r_1, t_1), (e_2, r_1, t_1), ..(e_n, r_1, t_1)] of shape (1, n_entity, 3)\n",
    "        student_common_head_sample, _ = distillation_process.mini_batch_student_head(\n",
    "            teacher_relation=relation, teacher_tail=tail)\n",
    "        \n",
    "        # Limiting the number of sample to distill entities\n",
    "        # Supposing the ground truth is (e3, r1, t4)\n",
    "        # Instead of construction [(e1, r1, t4), (e2, r1, t4), ..(en, r1, t4)]\n",
    "        # We construct [(e3, r1, t4), (e4, r1, t4), ..(e3+batch_size_entity, r1, t4)]\n",
    "        teacher_common_head_sample = teacher_common_head_sample[:,head:head+batch_size_entity]\n",
    "        student_common_head_sample = student_common_head_sample[:,head:head+batch_size_entity]\n",
    "        \n",
    "        # It does not cost a lot of memory to store indexes. We store all indexes to compute scores \n",
    "        # once for the current batch to speed up the training processus.\n",
    "        teacher_head.append(teacher_common_head_sample)\n",
    "        student_head.append(student_common_head_sample)\n",
    "        \n",
    "        # Constructing the tensor dedicated to distillation of relation:\n",
    "        teacher_common_relation_sample, _ = distillation_process.mini_batch_teacher_relation(\n",
    "            head=head, tail=tail)\n",
    "\n",
    "        student_common_relation_sample, _ = distillation_process.mini_batch_student_relation(\n",
    "            teacher_head=head, teacher_tail=tail)\n",
    "\n",
    "        teacher_relation.append(teacher_common_relation_sample)\n",
    "        student_relation.append(student_common_relation_sample)\n",
    "        \n",
    "        # Constructing the tensor dedicated to distillation of TAIL:\n",
    "        teacher_common_tail_sample, _ = distillation_process.mini_batch_teacher_tail(\n",
    "            relation=relation, head=head)\n",
    "        \n",
    "        # tensor [(e_1, r_1, t_1), (e_1, r_1, t_2), ..(e_1, r_1, t_n)] of shape (1, n_entity, 3)\n",
    "        student_common_tail_sample, _ = distillation_process.mini_batch_student_tail(\n",
    "            teacher_relation=relation, teacher_head=head)\n",
    "        \n",
    "        teacher_common_tail_sample = teacher_common_tail_sample[:,tail:tail+batch_size_entity]\n",
    "        student_common_tail_sample = student_common_tail_sample[:,tail:tail+batch_size_entity]\n",
    "        \n",
    "        teacher_tail.append(teacher_common_tail_sample)\n",
    "        student_tail.append(student_common_tail_sample)\n",
    "    \n",
    "    \n",
    "    # Create tensor [[(e_1, r_1, t_1),..(en, r_1, t_1)], ..,[(e1, r_3, t_2),..(e_n, r_3, t_2)]]\n",
    "    # Tensor of size (batch_size, number of entity needed to compute the distribution probability, 3)\n",
    "    teacher_head_tensor = torch.stack(teacher_head).reshape(len(teacher_head), batch_size_entity, 3).to(device)\n",
    "    student_head_tensor = torch.stack(student_head).reshape(len(student_head), batch_size_entity, 3).to(device)\n",
    "    \n",
    "    teacher_relation_tensor = torch.stack(teacher_relation).reshape(len(teacher_relation), wn18rr.n_relation, 3).to(device)\n",
    "    student_relation_tensor = torch.stack(student_relation).reshape(len(student_relation), wn18rr.n_relation, 3).to(device)\n",
    "    \n",
    "    teacher_tail_tensor = torch.stack(teacher_tail).reshape(len(teacher_tail), batch_size_entity, 3).to(device)\n",
    "    student_tail_tensor = torch.stack(student_tail).reshape(len(student_tail), batch_size_entity, 3).to(device)\n",
    "  \n",
    "    # Distillation loss of heads\n",
    "    loss_head = loss.KlDivergence()(\n",
    "        teacher_score=teacher.distill(teacher_head_tensor), \n",
    "        student_score=student.distill(student_head_tensor)\n",
    "    ) \n",
    "    \n",
    "    # Distillation loss of relations.\n",
    "    loss_relation = loss.KlDivergence()(\n",
    "        teacher_score=teacher.distill(teacher_relation_tensor), \n",
    "        student_score=student.distill(student_relation_tensor)\n",
    "    ) \n",
    "    \n",
    "    # Distillation loss of tails.\n",
    "    loss_tail = loss.KlDivergence()(\n",
    "        teacher_score=teacher.distill(teacher_tail_tensor), \n",
    "        student_score=student.distill(student_tail_tensor)\n",
    "    ) \n",
    "    \n",
    "    # The loss of the student is equal to the sum of all losses.\n",
    "    loss_student = loss_head + loss_relation + loss_tail\n",
    "    \n",
    "    metric.update(loss_student.item())\n",
    "    \n",
    "    loss_student.backward()\n",
    "\n",
    "    optimizer_student.step()\n",
    "    \n",
    "    if step % 5 == 0:\n",
    "    \n",
    "        bar.set_description(f'Metric: {metric.get():6f}')\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        \n",
    "        student = student.eval()\n",
    "        \n",
    "        score = evaluation.Evaluation()(model=student, dataset=wn18rr.test_dataset(batch_size=2), device=device)\n",
    "        \n",
    "        print(score)\n",
    "        \n",
    "        with open(f'./models/student_wn18rr_{score}.pickle', 'wb') as handle:\n",
    "            \n",
    "            pickle.dump(student, handle, protocol = pickle.HIGHEST_PROTOCOL)    \n",
    "        \n",
    "        student = student.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
